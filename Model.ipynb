{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "from datetime import datetime, date\n",
    "from os import path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load data, oversampled, 700 time units\n",
    "# X_train_temporal = np.load('feature_temporal_cat_oversample_standardscalar_X_train.npy')[:,:700,:]\n",
    "# X_train_cat = np.load('feature_temporal_cat_oversample_X_train.npy')[:,700:,1]\n",
    "\n",
    "# X_test_temporal = np.load('features_temporal_test_norm_standardscalar.npy')\n",
    "# X_test_cat = np.load('X_test_cat_features.npy')\n",
    "\n",
    "# y_train = np.load('feature_temporal_cat_oversample_standardscalar_y_train.npy')\n",
    "# y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load data, oversampled, 35 time units\n",
    "X_train_temporal = np.load('feature_temporal_cat_agg_oversample_standardscalar_X_train.npy')[:,:35,:]\n",
    "X_train_cat = np.load('feature_temporal_cat_agg_oversample_standardscalar_X_train.npy')[:,35:,1]\n",
    "\n",
    "X_test_temporal = np.load('features_temporal_test_norm_agg_standardscalar.npy')\n",
    "X_test_cat = np.load('X_test_cat_features.npy')\n",
    "\n",
    "y_train = np.load('feature_temporal_cat_agg_oversample_standardscalar_y_train.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 35, 7)\n",
      "(30, 35, 7)\n",
      "(350, 68)\n",
      "(30, 68)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_temporal.shape)\n",
    "print(X_test_temporal.shape)\n",
    "print(X_train_cat.shape)\n",
    "print(X_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = Input(shape=(X_train_temporal.shape[1], X_train_temporal.shape[2]), name='main_input')\n",
    "lstm_out = LSTM(50, dropout=0.1, recurrent_dropout=0.1)(main_input)\n",
    "\n",
    "auxiliary_input = Input(shape=(X_train_cat.shape[1],), name='aux_input')\n",
    "# aux_1 = Dense(30, activation='relu')(auxiliary_input)\n",
    "# aux_1= Dropout(0.1)(aux_1)\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "# stack a deep densely-connected network on top\n",
    "# x = Dense(8, activation='relu')(x)\n",
    "# x= Dropout(0.1)(x)\n",
    "x = Dense(3, activation='relu')(x)\n",
    "x= Dropout(0.1)(x)\n",
    "\n",
    "\n",
    "# add the main logistic regression layer\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "#This defines a model with two inputs:\n",
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         [(None, 35, 7)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 50)           11600       main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          [(None, 68)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 118)          0           lstm[0][0]                       \n",
      "                                                                 aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            357         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 3)            0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            4           dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,961\n",
      "Trainable params: 11,961\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.04612684,  0.12810898, -0.04923405, ...,  0.13690898,\n",
       "         -0.01092963, -0.0668384 ],\n",
       "        [-0.00968625,  0.11631796, -0.00224152, ..., -0.00431021,\n",
       "          0.14576605,  0.14549384],\n",
       "        [-0.1059039 , -0.12848085, -0.10927244, ..., -0.1245803 ,\n",
       "         -0.13252679,  0.00027959],\n",
       "        ...,\n",
       "        [ 0.1469158 ,  0.04715782,  0.02248803, ...,  0.13195059,\n",
       "          0.08830503,  0.16287541],\n",
       "        [-0.00210904,  0.11532283,  0.12712407, ..., -0.05299948,\n",
       "          0.06868903,  0.10984525],\n",
       "        [-0.16858229,  0.1077919 , -0.16498628, ..., -0.09779214,\n",
       "          0.1513162 ,  0.08627304]], dtype=float32),\n",
       " array([[-0.05075526, -0.02191966, -0.01147518, ..., -0.04134241,\n",
       "         -0.01154169,  0.03756327],\n",
       "        [ 0.0201015 ,  0.00538969,  0.08554165, ...,  0.03188874,\n",
       "         -0.05273901,  0.02144886],\n",
       "        [-0.08442931, -0.08168819, -0.00130725, ...,  0.0760088 ,\n",
       "         -0.00403816, -0.07845777],\n",
       "        ...,\n",
       "        [-0.13860554, -0.01448477, -0.0025478 , ..., -0.11653385,\n",
       "          0.02280872, -0.0717646 ],\n",
       "        [ 0.09829064,  0.1197098 ,  0.03341476, ...,  0.11597752,\n",
       "          0.03704066, -0.07032111],\n",
       "        [ 0.01882662, -0.07329441,  0.01595074, ..., -0.09782135,\n",
       "         -0.01468223,  0.10712899]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.04987553, -0.07307018,  0.20026655],\n",
       "        [ 0.21015708, -0.06765912,  0.03569396],\n",
       "        [-0.04178664,  0.21597631,  0.07119559],\n",
       "        [-0.0682735 ,  0.17137848,  0.04271589],\n",
       "        [-0.16731286,  0.00196841, -0.1859352 ],\n",
       "        [-0.07329933, -0.01003914, -0.01251085],\n",
       "        [-0.14615741, -0.21904424,  0.18824275],\n",
       "        [ 0.1618727 ,  0.160502  , -0.18576398],\n",
       "        [-0.0659771 ,  0.10811068, -0.12552552],\n",
       "        [-0.21146795, -0.12108863, -0.16973159],\n",
       "        [-0.06260574, -0.14948183,  0.03770445],\n",
       "        [ 0.05470057,  0.04731043,  0.22198586],\n",
       "        [-0.14249748, -0.05140996, -0.16358739],\n",
       "        [-0.12342858,  0.0935239 ,  0.09332179],\n",
       "        [-0.08440183, -0.03019056,  0.11411668],\n",
       "        [-0.04741856, -0.14559847,  0.08873238],\n",
       "        [ 0.07130463,  0.09812327,  0.14808829],\n",
       "        [-0.09851391, -0.02263795,  0.20573358],\n",
       "        [-0.17245454,  0.01479425, -0.0651546 ],\n",
       "        [-0.22155152,  0.17172112, -0.19433662],\n",
       "        [-0.13390008,  0.22030558, -0.22265577],\n",
       "        [ 0.10828649,  0.21206369, -0.1739481 ],\n",
       "        [ 0.06488405, -0.17653295,  0.01624608],\n",
       "        [-0.15031129, -0.1274769 ,  0.12840818],\n",
       "        [-0.22048959,  0.10354663, -0.12137883],\n",
       "        [-0.19082846,  0.12348278, -0.05485389],\n",
       "        [-0.01324797, -0.05226909, -0.16060886],\n",
       "        [-0.15909502,  0.09768175, -0.11730264],\n",
       "        [ 0.00697024,  0.13119759, -0.00355154],\n",
       "        [-0.04648596,  0.18472122, -0.11947875],\n",
       "        [ 0.04710634,  0.05169447, -0.18825683],\n",
       "        [-0.14903629, -0.20446612,  0.14308818],\n",
       "        [ 0.08034252, -0.04069854,  0.11623015],\n",
       "        [ 0.04663314, -0.01736775,  0.13982831],\n",
       "        [-0.18434256,  0.10303842,  0.14348598],\n",
       "        [-0.19649224,  0.09227259,  0.08057736],\n",
       "        [ 0.0163493 , -0.19092248,  0.01282164],\n",
       "        [ 0.08094956,  0.17520316, -0.04073364],\n",
       "        [-0.06510007,  0.19024317, -0.2117091 ],\n",
       "        [ 0.173039  , -0.18584734,  0.1638674 ],\n",
       "        [-0.05184664,  0.1150891 , -0.1569667 ],\n",
       "        [-0.17017835, -0.00442797,  0.15536462],\n",
       "        [-0.03293352, -0.16074935, -0.0897572 ],\n",
       "        [-0.04437405, -0.03910601, -0.18982774],\n",
       "        [ 0.19822015, -0.1798759 , -0.12974638],\n",
       "        [ 0.04554571,  0.11368783, -0.03207402],\n",
       "        [-0.07718678,  0.21346976,  0.06773017],\n",
       "        [-0.10931496, -0.04200692, -0.19503891],\n",
       "        [-0.03502733,  0.20568399,  0.11417334],\n",
       "        [-0.0656337 ,  0.19613557, -0.04790276],\n",
       "        [ 0.20297687,  0.0824451 , -0.20323786],\n",
       "        [-0.05202895,  0.07692079, -0.04232249],\n",
       "        [ 0.0591072 ,  0.05380093,  0.16931821],\n",
       "        [-0.12938775,  0.18439944, -0.01895863],\n",
       "        [ 0.04169799, -0.02578573,  0.14296861],\n",
       "        [ 0.05810906,  0.02129735, -0.17070507],\n",
       "        [-0.09653583, -0.13760245, -0.13682935],\n",
       "        [-0.11631297, -0.09537069,  0.04370739],\n",
       "        [ 0.11275069, -0.11240237, -0.03055742],\n",
       "        [ 0.17723449,  0.05779441,  0.14858757],\n",
       "        [-0.09894904, -0.08130491, -0.03612447],\n",
       "        [-0.07002933, -0.01920407, -0.12210942],\n",
       "        [-0.11959258, -0.20594265,  0.00246254],\n",
       "        [ 0.0264035 ,  0.01349367, -0.18417294],\n",
       "        [ 0.17831571,  0.023221  , -0.18145275],\n",
       "        [-0.12459265, -0.14606073, -0.14533928],\n",
       "        [-0.07067513,  0.14690621, -0.06170665],\n",
       "        [ 0.1586336 ,  0.13430156,  0.13491605],\n",
       "        [-0.17944665,  0.0592164 ,  0.12776847],\n",
       "        [ 0.10122736,  0.11791538, -0.03258401],\n",
       "        [-0.05432005, -0.00158052,  0.04193561],\n",
       "        [-0.16794741, -0.08643061, -0.00983356],\n",
       "        [ 0.1773891 ,  0.03679319, -0.21965352],\n",
       "        [ 0.12472735, -0.19194056, -0.10102905],\n",
       "        [ 0.20792131,  0.21582101,  0.15564896],\n",
       "        [ 0.17522259, -0.03300343,  0.03630169],\n",
       "        [ 0.12636457,  0.0484762 , -0.1381923 ],\n",
       "        [ 0.16186358, -0.09396441,  0.08379032],\n",
       "        [ 0.2063547 ,  0.09902211, -0.07928792],\n",
       "        [-0.14443164,  0.03278996, -0.09127465],\n",
       "        [-0.19992024, -0.09441186, -0.18639603],\n",
       "        [-0.14753637,  0.16158925, -0.06681854],\n",
       "        [ 0.10005899,  0.02579714,  0.2135907 ],\n",
       "        [-0.17063053, -0.21092817,  0.07491066],\n",
       "        [-0.12334586,  0.10837467,  0.12930377],\n",
       "        [ 0.02983485, -0.2223292 ,  0.16406934],\n",
       "        [ 0.09288497,  0.0821652 , -0.00161217],\n",
       "        [-0.10273313, -0.15454914,  0.05793749],\n",
       "        [-0.06425534,  0.07891305, -0.03142785],\n",
       "        [-0.16354503,  0.00303915,  0.02191252],\n",
       "        [ 0.10956864,  0.04320247, -0.19352725],\n",
       "        [ 0.16716655,  0.126889  , -0.12608516],\n",
       "        [ 0.08821802,  0.13829343, -0.19691612],\n",
       "        [ 0.04219817, -0.07015882,  0.01777607],\n",
       "        [ 0.16602896,  0.11730738,  0.05042417],\n",
       "        [ 0.09026922, -0.01612025,  0.07151638],\n",
       "        [-0.15494557, -0.15317252, -0.00346097],\n",
       "        [ 0.16824456,  0.17666318, -0.1699723 ],\n",
       "        [-0.10030665, -0.05782843, -0.16940391],\n",
       "        [ 0.17392005,  0.12502404,  0.04938383],\n",
       "        [-0.17056039, -0.14330424,  0.09853308],\n",
       "        [ 0.08670191, -0.03850305, -0.221892  ],\n",
       "        [ 0.14809237,  0.20666696, -0.2019944 ],\n",
       "        [-0.09800939, -0.08174467,  0.07654651],\n",
       "        [-0.13634823,  0.18970467, -0.10155381],\n",
       "        [ 0.15152107,  0.06289451, -0.07364868],\n",
       "        [-0.11576087, -0.09694113, -0.05115141],\n",
       "        [-0.15390344,  0.19290264,  0.01043795],\n",
       "        [ 0.13291667,  0.00195806,  0.06850259],\n",
       "        [ 0.08895673,  0.05586983, -0.15200192],\n",
       "        [-0.03394485,  0.01663513,  0.09075271],\n",
       "        [-0.01536864, -0.09442966, -0.03631251],\n",
       "        [-0.06127682, -0.17773712, -0.15319653],\n",
       "        [ 0.10212772, -0.19520526, -0.03019294],\n",
       "        [ 0.11303894, -0.0273307 , -0.09106643],\n",
       "        [ 0.08473243,  0.05682893,  0.17551376],\n",
       "        [ 0.17074923,  0.11283691, -0.05537695],\n",
       "        [ 0.04880564, -0.20449618,  0.20527475]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 1.079182  ],\n",
       "        [ 0.57060134],\n",
       "        [-0.07889128]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model.output_shape\n",
    "# Model summary\n",
    "model.summary()\n",
    "# Model config\n",
    "model.get_config()\n",
    "# List all weight tensors \n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nanelia/opt/anaconda3/envs/my-project/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:357: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 [==============================] - 18s 409ms/step - loss: 0.7614 - accuracy: 0.4833 - mean_pred: 0.5670 - val_loss: 0.5929 - val_accuracy: 0.5714 - val_mean_pred: 0.5582\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59288, saving model to lstm.hdf5\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7690 - accuracy: 0.4677 - mean_pred: 0.5728 - val_loss: 0.5955 - val_accuracy: 0.5714 - val_mean_pred: 0.5566\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.59288\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7499 - accuracy: 0.4588 - mean_pred: 0.5602 - val_loss: 0.5979 - val_accuracy: 0.5714 - val_mean_pred: 0.5552\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.59288\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7691 - accuracy: 0.4921 - mean_pred: 0.5674 - val_loss: 0.6003 - val_accuracy: 0.5143 - val_mean_pred: 0.5538\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.59288\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7626 - accuracy: 0.5057 - mean_pred: 0.5700 - val_loss: 0.6024 - val_accuracy: 0.5143 - val_mean_pred: 0.5525\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.59288\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7456 - accuracy: 0.4850 - mean_pred: 0.5643 - val_loss: 0.6046 - val_accuracy: 0.5143 - val_mean_pred: 0.5513\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.59288\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7641 - accuracy: 0.4720 - mean_pred: 0.5617 - val_loss: 0.6052 - val_accuracy: 0.5143 - val_mean_pred: 0.5509\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.59288\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7626 - accuracy: 0.4496 - mean_pred: 0.5642 - val_loss: 0.6058 - val_accuracy: 0.5143 - val_mean_pred: 0.5505\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.59288\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7608 - accuracy: 0.5005 - mean_pred: 0.5633 - val_loss: 0.6065 - val_accuracy: 0.5143 - val_mean_pred: 0.5502\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.59288\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7601 - accuracy: 0.4472 - mean_pred: 0.5657 - val_loss: 0.6071 - val_accuracy: 0.5143 - val_mean_pred: 0.5498\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.59288\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7515 - accuracy: 0.4691 - mean_pred: 0.5608 - val_loss: 0.6078 - val_accuracy: 0.5143 - val_mean_pred: 0.5494\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.59288\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7581 - accuracy: 0.4717 - mean_pred: 0.5615 - val_loss: 0.6080 - val_accuracy: 0.5143 - val_mean_pred: 0.5493\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.59288\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7540 - accuracy: 0.4745 - mean_pred: 0.5630 - val_loss: 0.6082 - val_accuracy: 0.5143 - val_mean_pred: 0.5492\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.59288\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7504 - accuracy: 0.4373 - mean_pred: 0.5557 - val_loss: 0.6084 - val_accuracy: 0.5143 - val_mean_pred: 0.5490\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.59288\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7600 - accuracy: 0.5009 - mean_pred: 0.5623 - val_loss: 0.6086 - val_accuracy: 0.5143 - val_mean_pred: 0.5489\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.59288\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7493 - accuracy: 0.4855 - mean_pred: 0.5595 - val_loss: 0.6087 - val_accuracy: 0.5143 - val_mean_pred: 0.5488\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.59288\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7621 - accuracy: 0.4756 - mean_pred: 0.5602 - val_loss: 0.6088 - val_accuracy: 0.5143 - val_mean_pred: 0.5488\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.59288\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7561 - accuracy: 0.4893 - mean_pred: 0.5618 - val_loss: 0.6089 - val_accuracy: 0.5143 - val_mean_pred: 0.5488\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.59288\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7514 - accuracy: 0.4710 - mean_pred: 0.5615 - val_loss: 0.6089 - val_accuracy: 0.5143 - val_mean_pred: 0.5487\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.59288\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7458 - accuracy: 0.4415 - mean_pred: 0.5597 - val_loss: 0.6090 - val_accuracy: 0.5143 - val_mean_pred: 0.5487\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.59288\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7642 - accuracy: 0.4699 - mean_pred: 0.5643 - val_loss: 0.6090 - val_accuracy: 0.5143 - val_mean_pred: 0.5487\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.59288\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7429 - accuracy: 0.4963 - mean_pred: 0.5569 - val_loss: 0.6090 - val_accuracy: 0.5143 - val_mean_pred: 0.5487\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.59288\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7480 - accuracy: 0.4902 - mean_pred: 0.5578 - val_loss: 0.6091 - val_accuracy: 0.5143 - val_mean_pred: 0.5486\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.59288\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7722 - accuracy: 0.4390 - mean_pred: 0.5616 - val_loss: 0.6091 - val_accuracy: 0.5143 - val_mean_pred: 0.5486\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.59288\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7547 - accuracy: 0.4774 - mean_pred: 0.5648 - val_loss: 0.6091 - val_accuracy: 0.5143 - val_mean_pred: 0.5486\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.59288\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7312 - accuracy: 0.4913 - mean_pred: 0.5603 - val_loss: 0.6091 - val_accuracy: 0.5143 - val_mean_pred: 0.5486\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.59288\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7580 - accuracy: 0.4566 - mean_pred: 0.5598 - val_loss: 0.6091 - val_accuracy: 0.5143 - val_mean_pred: 0.5486\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.59288\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7600 - accuracy: 0.4712 - mean_pred: 0.5631 - val_loss: 0.6092 - val_accuracy: 0.5143 - val_mean_pred: 0.5486\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.59288\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7442 - accuracy: 0.5110 - mean_pred: 0.5586 - val_loss: 0.6092 - val_accuracy: 0.5143 - val_mean_pred: 0.5486\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.59288\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7508 - accuracy: 0.4824 - mean_pred: 0.5612 - val_loss: 0.6092 - val_accuracy: 0.5143 - val_mean_pred: 0.5486\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.59288\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.optimizers import adam_v2\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "opt = adam_v2.Adam(lr=0.0001)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss={'main_output': 'binary_crossentropy'},metrics=['accuracy',mean_pred])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath='lstm.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "history=model.fit({'main_input': X_train_temporal, 'aux_input': X_train_cat},\n",
    "          {'main_output': y_train},\n",
    "          epochs=30, batch_size=128, callbacks=[reduce_lr, checkpointer],validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('lstm.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = model.predict({'main_input': X_test_temporal, 'aux_input': X_test_cat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, average_precision_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7120000000000001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6055203619909502"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.32      0.47        25\n",
      "           1       0.19      0.80      0.31         5\n",
      "\n",
      "    accuracy                           0.40        30\n",
      "   macro avg       0.54      0.56      0.39        30\n",
      "weighted avg       0.77      0.40      0.44        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, (y_score>0.5).astype(int)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-project",
   "language": "python",
   "name": "my-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
