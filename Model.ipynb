{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "from datetime import datetime, date\n",
    "from os import path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load data, oversampled, 700 time units\n",
    "# X_train_temporal = np.load('feature_temporal_cat_oversample_standardscalar_X_train.npy')[:,:700,:]\n",
    "# X_train_cat = np.load('feature_temporal_cat_oversample_X_train.npy')[:,700:,1]\n",
    "\n",
    "# X_test_temporal = np.load('features_temporal_test_norm_standardscalar.npy')\n",
    "# X_test_cat = np.load('X_test_cat_features.npy')\n",
    "\n",
    "# y_train = np.load('feature_temporal_cat_oversample_standardscalar_y_train.npy')\n",
    "# y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load data, oversampled, 35 time units\n",
    "X_train_temporal = np.load('feature_temporal_cat_agg_oversample_standardscalar_X_train.npy')[:,:35,:]\n",
    "X_train_cat = np.load('feature_temporal_cat_agg_oversample_standardscalar_X_train.npy')[:,35:,1]\n",
    "\n",
    "X_test_temporal = np.load('features_temporal_test_norm_agg_standardscalar.npy')\n",
    "X_test_cat = np.load('X_test_cat_features.npy')\n",
    "\n",
    "y_train = np.load('feature_temporal_cat_agg_oversample_standardscalar_y_train.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 35, 7)\n",
      "(30, 35, 7)\n",
      "(350, 68)\n",
      "(30, 68)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_temporal.shape)\n",
    "print(X_test_temporal.shape)\n",
    "print(X_train_cat.shape)\n",
    "print(X_test_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = Input(shape=(X_train_temporal.shape[1], X_train_temporal.shape[2]), name='main_input')\n",
    "lstm_out = LSTM(50, dropout=0.1, recurrent_dropout=0.1)(main_input)\n",
    "\n",
    "auxiliary_input = Input(shape=(X_train_cat.shape[1],), name='aux_input')\n",
    "# aux_1 = Dense(30, activation='relu')(auxiliary_input)\n",
    "# aux_1= Dropout(0.1)(aux_1)\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "# stack a deep densely-connected network on top\n",
    "x = Dense(8, activation='relu')(x)\n",
    "x= Dropout(0.1)(x)\n",
    "# x = Dense(3, activation='relu')(x)\n",
    "# x= Dropout(0.1)(x)\n",
    "\n",
    "\n",
    "# add the main logistic regression layer\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)\n",
    "#This defines a model with two inputs:\n",
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         [(None, 35, 7)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 50)           11600       main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "aux_input (InputLayer)          [(None, 68)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 118)          0           lstm[0][0]                       \n",
      "                                                                 aux_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 8)            952         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 8)            0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            9           dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,561\n",
      "Trainable params: 12,561\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.07638404,  0.04154107,  0.06486528, ...,  0.06169215,\n",
       "         -0.16041398,  0.0311897 ],\n",
       "        [-0.08862188, -0.1313782 , -0.07824925, ..., -0.12464054,\n",
       "         -0.06388788, -0.16331913],\n",
       "        [ 0.121438  , -0.08952495,  0.00792842, ..., -0.04797573,\n",
       "          0.06731211,  0.04915234],\n",
       "        ...,\n",
       "        [-0.07030415, -0.00492679, -0.05372164, ..., -0.07734483,\n",
       "          0.07170068,  0.1626527 ],\n",
       "        [ 0.0258173 ,  0.13877878,  0.14571011, ..., -0.01803985,\n",
       "          0.12262031, -0.04218626],\n",
       "        [-0.02379616,  0.13987708,  0.04139754, ...,  0.06552634,\n",
       "         -0.15832825, -0.00155692]], dtype=float32),\n",
       " array([[-0.0912993 , -0.00522477, -0.0505947 , ..., -0.08093317,\n",
       "          0.00284258,  0.03007905],\n",
       "        [ 0.14688835, -0.009341  ,  0.1375206 , ...,  0.07899708,\n",
       "         -0.0011789 ,  0.04956714],\n",
       "        [-0.02023003,  0.02591759, -0.04390585, ...,  0.0511161 ,\n",
       "          0.00305995,  0.06004294],\n",
       "        ...,\n",
       "        [ 0.02202007,  0.0068798 , -0.08931717, ...,  0.02045628,\n",
       "         -0.00882064, -0.01785352],\n",
       "        [-0.00404339, -0.02566821, -0.07801651, ..., -0.01231163,\n",
       "         -0.12708226, -0.01497393],\n",
       "        [-0.01623625, -0.06564318,  0.08478357, ...,  0.0401419 ,\n",
       "          0.07390925,  0.00085982]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 1.19781032e-01,  9.97080356e-02, -9.79083255e-02,\n",
       "          6.06520623e-02, -8.39497894e-02, -1.98918149e-01,\n",
       "         -1.81153715e-01, -8.59368593e-02],\n",
       "        [ 2.00358167e-01,  4.11588103e-02, -2.39453167e-02,\n",
       "         -1.48519874e-01,  9.81816798e-02,  1.66118339e-01,\n",
       "          1.63515821e-01,  9.40067917e-02],\n",
       "        [ 4.16198224e-02, -1.54636383e-01, -1.30122066e-01,\n",
       "          2.60581821e-02,  1.74624160e-01,  1.55328915e-01,\n",
       "         -8.61815959e-02, -1.05393581e-01],\n",
       "        [-2.11351812e-01, -2.15014160e-01,  1.41486153e-01,\n",
       "          3.37245911e-02,  2.07445100e-01,  6.12193197e-02,\n",
       "         -3.04621905e-02,  1.90580621e-01],\n",
       "        [ 3.70831639e-02, -1.88637078e-02,  1.94506183e-01,\n",
       "         -1.25315726e-01, -6.15637898e-02, -7.09229559e-02,\n",
       "          1.00196004e-02, -1.48247302e-01],\n",
       "        [ 1.98075667e-01, -1.73279762e-01,  1.53143108e-02,\n",
       "          7.37214535e-02, -1.97555810e-01,  2.08116546e-01,\n",
       "         -1.59831926e-01,  4.77067083e-02],\n",
       "        [ 1.69278607e-01, -4.25696373e-02, -9.71106961e-02,\n",
       "          3.39827091e-02, -6.82703555e-02, -1.19849548e-01,\n",
       "          8.54735523e-02,  3.30346674e-02],\n",
       "        [ 9.02692825e-02,  1.57818064e-01, -1.50656313e-01,\n",
       "          1.58521429e-01, -1.51786029e-01, -1.09630413e-01,\n",
       "          9.20179486e-03, -4.56278473e-02],\n",
       "        [-1.96524426e-01, -2.15493381e-01,  6.01786226e-02,\n",
       "         -1.05706006e-01,  3.73964757e-02, -1.01878673e-01,\n",
       "          7.88352638e-02,  1.07894987e-02],\n",
       "        [-1.61878005e-01,  1.14221707e-01, -4.68437374e-02,\n",
       "          2.48705596e-02, -8.97101313e-02,  1.39431611e-01,\n",
       "         -5.27395010e-02,  5.21550924e-02],\n",
       "        [-1.98477060e-02,  1.56328157e-01,  1.92882672e-01,\n",
       "         -8.28635097e-02,  8.51980895e-02, -3.88153642e-02,\n",
       "         -1.41088665e-01,  2.02502906e-02],\n",
       "        [ 2.40376592e-03,  4.43361253e-02,  1.35531381e-01,\n",
       "          6.01933897e-03,  1.97829053e-01, -5.52567840e-02,\n",
       "          3.08165401e-02,  9.53061432e-02],\n",
       "        [-1.83391035e-01,  4.62880284e-02, -9.40460339e-02,\n",
       "          1.26356438e-01, -8.60956460e-02,  5.95128089e-02,\n",
       "          1.13401130e-01, -7.53073394e-03],\n",
       "        [-1.88618302e-02,  1.15144506e-01,  2.08924338e-01,\n",
       "          2.09755406e-01, -9.67215821e-02,  1.66599259e-01,\n",
       "         -5.01721650e-02,  4.07201052e-03],\n",
       "        [-7.34764040e-02, -1.23296455e-01,  1.27658531e-01,\n",
       "          9.19472426e-02, -1.34056821e-01,  8.86703283e-02,\n",
       "          5.72855920e-02, -1.94710970e-01],\n",
       "        [-1.68443829e-01, -1.85434371e-02,  1.69483438e-01,\n",
       "         -1.10906176e-01,  9.32056457e-02, -1.65795535e-02,\n",
       "         -1.31665394e-01,  6.99594766e-02],\n",
       "        [ 4.50859517e-02,  5.86508214e-03,  6.89707845e-02,\n",
       "         -6.27527088e-02, -5.35395294e-02, -1.36825144e-01,\n",
       "          7.49343187e-02, -1.35019124e-01],\n",
       "        [ 1.74623117e-01, -1.82151794e-03, -1.96517617e-01,\n",
       "          1.50951460e-01,  6.42516166e-02,  2.00175896e-01,\n",
       "          1.22031942e-01, -1.83112592e-01],\n",
       "        [ 5.80782741e-02,  7.50872046e-02, -1.84229985e-01,\n",
       "          2.41878033e-02, -1.36639148e-01, -1.84560925e-01,\n",
       "         -6.99330419e-02,  2.01973245e-01],\n",
       "        [ 2.03259125e-01, -1.53150290e-01,  6.88193291e-02,\n",
       "          1.56829968e-01,  1.48535267e-01, -4.45583910e-02,\n",
       "         -7.67455846e-02,  1.89136401e-01],\n",
       "        [ 1.90967724e-01,  2.05727145e-01, -1.17649838e-01,\n",
       "         -8.95170569e-02, -1.65126324e-01, -1.73345372e-01,\n",
       "          2.11804047e-01,  1.01596072e-01],\n",
       "        [ 1.61437243e-02,  1.33018419e-01, -1.76372826e-01,\n",
       "         -5.37988245e-02,  6.33134693e-02, -2.06739187e-01,\n",
       "          1.33342996e-01,  7.49934167e-02],\n",
       "        [ 2.06831381e-01, -2.06233278e-01, -1.83281481e-01,\n",
       "          1.55912831e-01, -4.26232815e-02, -1.28355265e-01,\n",
       "         -1.04089573e-01,  3.00682336e-02],\n",
       "        [-1.11029275e-01,  2.80674249e-02,  6.93938285e-02,\n",
       "         -2.19135433e-02,  8.47748369e-02,  1.78072497e-01,\n",
       "          1.96586713e-01,  3.28363925e-02],\n",
       "        [ 1.95625082e-01,  3.02527696e-02,  1.19417682e-01,\n",
       "          1.33328661e-01,  1.59282014e-01,  1.80226639e-01,\n",
       "         -4.66190279e-02, -1.10454060e-01],\n",
       "        [ 3.24238837e-03, -1.35765523e-02, -2.05448553e-01,\n",
       "         -3.67887467e-02,  2.11084351e-01,  1.86166063e-01,\n",
       "         -7.44253248e-02,  9.57577676e-02],\n",
       "        [-1.15407102e-01,  1.71448305e-01, -1.91043511e-01,\n",
       "         -1.77154273e-01, -1.59585327e-01,  1.72276512e-01,\n",
       "         -1.30300462e-01,  2.02932313e-01],\n",
       "        [ 1.96713805e-02, -1.11519054e-01,  1.26749590e-01,\n",
       "          1.18221000e-01,  3.31711918e-02, -1.37823164e-01,\n",
       "         -3.47205102e-02,  2.08433419e-02],\n",
       "        [-5.82866520e-02,  1.97434381e-01,  1.55328885e-01,\n",
       "          1.98626831e-01,  2.16551974e-01, -5.72155565e-02,\n",
       "          1.92130610e-01, -4.42920625e-02],\n",
       "        [-8.74930471e-02,  9.14650708e-02, -4.21286076e-02,\n",
       "          1.94841608e-01,  7.38161802e-03, -8.84350538e-02,\n",
       "         -8.39932263e-03,  1.33439198e-01],\n",
       "        [ 8.26800615e-02,  1.23504981e-01, -3.36203873e-02,\n",
       "         -2.06828833e-01, -3.35353315e-02, -7.13474005e-02,\n",
       "          2.70533115e-02,  1.29216775e-01],\n",
       "        [-8.43435824e-02,  5.69221228e-02, -1.61807403e-01,\n",
       "          3.97833139e-02,  1.75465181e-01, -1.92976326e-01,\n",
       "         -9.36819464e-02,  2.16521397e-01],\n",
       "        [ 2.08342373e-02, -1.88639805e-01, -1.14704058e-01,\n",
       "          1.05343893e-01,  1.80200204e-01, -1.79078728e-02,\n",
       "          1.88848481e-01,  1.35681167e-01],\n",
       "        [-6.32802695e-02, -1.51760697e-01, -1.55734167e-01,\n",
       "          1.03876010e-01, -2.06300125e-01,  8.32470208e-02,\n",
       "         -1.67361155e-01,  1.04123652e-02],\n",
       "        [-1.90764546e-01, -1.74300432e-01, -2.20533907e-02,\n",
       "         -5.55669218e-02,  5.66272289e-02,  4.85665649e-02,\n",
       "         -1.69552952e-01, -8.91716629e-02],\n",
       "        [ 1.40500709e-01,  7.33018070e-02, -1.09432712e-01,\n",
       "         -2.02722222e-01, -1.97641551e-01, -1.35212809e-01,\n",
       "         -1.52136534e-01,  1.82484388e-02],\n",
       "        [ 8.46443027e-02, -2.28901505e-02, -1.20613411e-01,\n",
       "          1.36583999e-01,  1.96674064e-01,  1.32124111e-01,\n",
       "          2.04275802e-01, -1.27789676e-02],\n",
       "        [ 1.30242392e-01,  9.99103934e-02,  1.24773398e-01,\n",
       "          2.03548267e-01,  2.00329721e-02, -1.66322008e-01,\n",
       "         -7.45836496e-02,  1.63445935e-01],\n",
       "        [-1.10063024e-01, -1.56023905e-01, -8.65292996e-02,\n",
       "          5.05655855e-02,  1.52490154e-01,  1.24169156e-01,\n",
       "          1.44077256e-01,  9.51897055e-02],\n",
       "        [-8.97562504e-03,  1.48811951e-01,  5.32216877e-02,\n",
       "         -7.18212575e-02,  2.80690342e-02,  8.04116875e-02,\n",
       "         -1.40802562e-01,  1.30028889e-01],\n",
       "        [ 1.87159106e-01, -6.71183616e-02,  3.97639126e-02,\n",
       "         -1.50314391e-01,  9.39377099e-02, -1.77113175e-01,\n",
       "          1.08733401e-01,  1.53674409e-01],\n",
       "        [-1.78255126e-01, -1.15178958e-01, -8.07132870e-02,\n",
       "          7.48239607e-02,  6.63872808e-02,  3.95063311e-02,\n",
       "          1.38216957e-01,  1.78139463e-01],\n",
       "        [ 7.32963830e-02, -9.79698747e-02,  3.25348526e-02,\n",
       "          1.98777929e-01,  1.76056936e-01, -1.49065167e-01,\n",
       "         -2.03415215e-01,  8.30592960e-02],\n",
       "        [ 1.58431664e-01,  3.81442755e-02, -1.50037438e-01,\n",
       "         -6.95118308e-02, -1.55419201e-01,  1.66411594e-01,\n",
       "          1.82977691e-01,  5.96827418e-02],\n",
       "        [-2.86778808e-03,  3.63628566e-03,  1.40160173e-02,\n",
       "         -9.10667926e-02, -1.46349445e-01, -4.64763641e-02,\n",
       "         -1.50135413e-01, -1.02587700e-01],\n",
       "        [-1.34135425e-01,  9.50924009e-02, -1.63863465e-01,\n",
       "          1.68215588e-01, -2.16931105e-02, -1.90721154e-01,\n",
       "          1.95420817e-01,  1.84590951e-01],\n",
       "        [ 1.81361362e-01, -4.76389676e-02, -8.76985043e-02,\n",
       "         -2.08754405e-01, -1.72035322e-01, -1.08621351e-01,\n",
       "          1.22742221e-01,  2.93999463e-02],\n",
       "        [-1.20034084e-01,  1.08450755e-01, -2.04003811e-01,\n",
       "         -3.57145369e-02,  1.53898075e-01, -8.85130465e-02,\n",
       "         -6.54425770e-02,  2.03074381e-01],\n",
       "        [ 5.44342250e-02,  5.58283478e-02, -1.43647194e-05,\n",
       "          1.93221465e-01, -7.57880211e-02,  1.30349949e-01,\n",
       "          2.58960724e-02, -8.48857611e-02],\n",
       "        [ 5.26236445e-02, -1.96803495e-01,  1.93113536e-02,\n",
       "          7.55059868e-02, -2.13093266e-01,  5.61093539e-02,\n",
       "          1.54210642e-01,  4.91059870e-02],\n",
       "        [-5.96353412e-02, -2.13006482e-01,  1.10900357e-01,\n",
       "          7.23506957e-02, -5.80764562e-02, -1.43178493e-01,\n",
       "         -2.10189939e-01,  1.70835629e-01],\n",
       "        [ 9.41794962e-02, -1.26926705e-01,  1.71275422e-01,\n",
       "         -4.27584052e-02, -9.69378054e-02,  4.90870923e-02,\n",
       "         -1.69694990e-01, -1.98691770e-01],\n",
       "        [ 8.56316835e-02, -9.77291390e-02, -1.67708129e-01,\n",
       "         -2.70330161e-02, -7.24602044e-02, -8.15598220e-02,\n",
       "         -1.29467249e-01,  3.51637155e-02],\n",
       "        [-7.03632534e-02, -1.73420653e-01,  1.99697152e-01,\n",
       "          5.50000221e-02, -7.68801719e-02,  2.15278670e-01,\n",
       "         -1.27019048e-01,  1.40987262e-01],\n",
       "        [ 1.33935228e-01,  1.25858858e-01,  1.69329032e-01,\n",
       "          1.94742128e-01, -8.51310194e-02,  1.93587080e-01,\n",
       "          2.05398664e-01, -9.77989659e-02],\n",
       "        [ 1.19321093e-01, -1.88930333e-01,  3.22286040e-02,\n",
       "         -5.77630401e-02, -4.68296260e-02,  2.04794988e-01,\n",
       "          1.07469872e-01, -1.60127729e-02],\n",
       "        [ 2.02977762e-01, -1.56857073e-03, -1.33201331e-01,\n",
       "          1.63575247e-01, -6.69334084e-02,  7.38077611e-02,\n",
       "         -1.73332840e-02,  8.66411477e-02],\n",
       "        [ 3.96459848e-02,  6.16997331e-02,  1.46535039e-03,\n",
       "          2.11206958e-01,  8.94160569e-03, -5.73858619e-04,\n",
       "          1.62271842e-01,  1.24764398e-01],\n",
       "        [-1.23248637e-01,  1.73135743e-01, -2.16969132e-01,\n",
       "         -8.52219611e-02,  1.32031247e-01, -5.21213114e-02,\n",
       "          1.66433081e-01,  1.89727709e-01],\n",
       "        [-7.32936263e-02,  6.60188645e-02, -1.10360049e-01,\n",
       "         -9.67937931e-02, -4.65363562e-02, -1.45104900e-01,\n",
       "         -1.85064375e-02,  1.22447982e-01],\n",
       "        [-1.27462685e-01,  6.73961490e-02, -5.45794964e-02,\n",
       "         -1.91807896e-01,  2.05615148e-01,  4.56665009e-02,\n",
       "         -2.18207836e-02,  1.21255949e-01],\n",
       "        [ 1.64156899e-01, -1.41518876e-01,  4.65358943e-02,\n",
       "         -1.60466924e-01,  1.56949088e-01, -3.11429650e-02,\n",
       "         -2.15296313e-01, -1.88286588e-01],\n",
       "        [-1.45323575e-01, -1.89391285e-01, -1.58201039e-01,\n",
       "          2.46468484e-02, -1.10685788e-01, -1.91915125e-01,\n",
       "         -1.50477126e-01,  1.41867697e-02],\n",
       "        [ 2.16961965e-01,  2.39128470e-02,  6.36318773e-02,\n",
       "          1.73693106e-01, -1.74302772e-01,  7.69789517e-03,\n",
       "         -6.19279295e-02,  1.38901010e-01],\n",
       "        [ 2.22101063e-02, -1.95113912e-01, -7.95589387e-03,\n",
       "          9.32368636e-03,  4.56578881e-02, -7.83978701e-02,\n",
       "          1.28260553e-02, -5.34199625e-02],\n",
       "        [ 1.16401017e-02,  8.71586651e-02,  1.06578663e-01,\n",
       "         -1.80303439e-01,  1.81707844e-01, -7.47788548e-02,\n",
       "         -2.12490737e-01, -7.56274611e-02],\n",
       "        [-1.18703961e-01, -2.07226157e-01,  1.90101936e-01,\n",
       "         -1.62681401e-01, -1.37032047e-01, -3.17227989e-02,\n",
       "          9.51467603e-02,  2.12794840e-02],\n",
       "        [ 1.46022543e-01, -6.19690716e-02, -1.91392198e-01,\n",
       "          7.86879212e-02, -1.15901411e-01,  1.57026306e-01,\n",
       "          1.03377327e-01,  1.40807822e-01],\n",
       "        [-1.38918042e-01, -1.30126998e-01, -1.58581346e-01,\n",
       "         -1.28401786e-01, -2.07226008e-01,  1.70372441e-01,\n",
       "          1.65751263e-01,  9.86386389e-02],\n",
       "        [ 2.68320888e-02, -1.97224081e-01, -1.44598782e-01,\n",
       "          1.99998066e-01,  2.03219637e-01, -1.53083429e-01,\n",
       "         -7.08132833e-02, -1.78932667e-01],\n",
       "        [-1.13122374e-01, -1.98598027e-01, -4.30173427e-02,\n",
       "          3.06374133e-02, -1.13635577e-01,  3.57810408e-02,\n",
       "          1.61748990e-01, -2.79291868e-02],\n",
       "        [-2.06937879e-01, -4.11166847e-02, -1.89057529e-01,\n",
       "         -5.21260053e-02, -1.71468228e-01, -1.20905019e-01,\n",
       "          7.69851655e-02, -7.79650509e-02],\n",
       "        [ 1.72663495e-01,  4.17275280e-02, -1.10716969e-02,\n",
       "         -1.09682806e-01,  1.04262531e-02, -3.80274653e-02,\n",
       "         -1.82356328e-01,  1.70173630e-01],\n",
       "        [-1.19738050e-01,  1.88574359e-01, -1.46740898e-01,\n",
       "          6.30943626e-02, -1.47831336e-01, -4.02847677e-02,\n",
       "          4.34743911e-02, -2.12027431e-01],\n",
       "        [ 2.14527652e-01,  1.70952693e-01,  2.05944940e-01,\n",
       "          1.60870925e-01,  4.21674103e-02,  2.16073707e-01,\n",
       "         -1.58039182e-01, -1.57438576e-01],\n",
       "        [ 4.43464518e-03, -1.98018596e-01,  1.53110370e-01,\n",
       "         -1.39432400e-02, -1.67435855e-01,  8.33652169e-02,\n",
       "         -1.99022561e-01,  9.77042764e-02],\n",
       "        [-1.14391945e-01,  7.53827244e-02,  1.87215209e-03,\n",
       "         -1.04020111e-01, -1.60026401e-01, -1.14978030e-01,\n",
       "         -7.66487122e-02, -1.21754006e-01],\n",
       "        [-3.72000039e-03,  1.62661955e-01, -2.13532120e-01,\n",
       "          1.16357520e-01,  1.51213005e-01, -1.79561585e-01,\n",
       "         -9.56615806e-02,  3.89216095e-02],\n",
       "        [ 4.14234251e-02,  2.18199059e-01, -6.64464384e-02,\n",
       "         -3.71099114e-02,  5.25923818e-02, -7.50392675e-04,\n",
       "          1.26483753e-01,  1.94080070e-01],\n",
       "        [-1.34471625e-01, -1.35582060e-01,  8.24760050e-02,\n",
       "          2.74809301e-02,  2.14799717e-01,  1.66536421e-02,\n",
       "          2.04287454e-01, -8.30515474e-02],\n",
       "        [ 2.29013264e-02,  1.91720590e-01,  1.56629905e-01,\n",
       "         -7.86742866e-02, -1.55653685e-01,  1.06416538e-01,\n",
       "          2.08874896e-01, -2.11628497e-01],\n",
       "        [-1.09730050e-01,  1.65152386e-01,  8.51088017e-02,\n",
       "         -7.55026042e-02,  1.83696762e-01, -1.63630843e-01,\n",
       "         -5.29986471e-02,  1.18085608e-01],\n",
       "        [ 1.74915299e-01,  1.17645666e-01,  1.12688199e-01,\n",
       "          1.45408884e-01, -1.79140940e-01,  1.80815086e-01,\n",
       "          5.65769225e-02,  1.46191999e-01],\n",
       "        [-1.23634107e-01, -2.89848745e-02, -3.45651507e-02,\n",
       "          2.13354126e-01,  1.56450048e-01,  3.70528251e-02,\n",
       "         -1.99776337e-01,  1.88450322e-01],\n",
       "        [-1.18964769e-01, -1.60457194e-01, -1.30786955e-01,\n",
       "         -4.35960293e-02, -6.37241602e-02,  7.78195411e-02,\n",
       "          1.47016838e-01,  1.22917891e-02],\n",
       "        [ 1.42934576e-01, -1.74112171e-02,  1.78668216e-01,\n",
       "         -1.25222653e-02,  1.76865324e-01,  1.80010274e-01,\n",
       "          1.57958731e-01, -3.07838172e-02],\n",
       "        [-1.62472412e-01, -1.16822965e-01, -4.98747379e-02,\n",
       "         -5.00439107e-03,  1.29258484e-02,  9.82065946e-02,\n",
       "          1.32586703e-01,  9.45025235e-02],\n",
       "        [ 1.76210925e-01, -1.20973177e-01,  4.84005362e-02,\n",
       "         -1.40789866e-01,  3.27163786e-02, -1.40419438e-01,\n",
       "          1.67492673e-01, -8.32495093e-02],\n",
       "        [ 7.20320195e-02,  9.61189419e-02, -5.45536429e-02,\n",
       "         -1.98834121e-01,  1.67812422e-01,  9.50799137e-02,\n",
       "          1.18995354e-01,  1.66386679e-01],\n",
       "        [-1.36579454e-01,  5.95732778e-02, -2.81303823e-02,\n",
       "         -3.18204612e-02, -7.32028484e-02,  1.84592083e-01,\n",
       "          9.00677592e-02, -7.47666806e-02],\n",
       "        [ 2.93892771e-02, -8.54520202e-02, -2.05298603e-01,\n",
       "         -8.71859789e-02, -1.99913159e-01, -2.13605165e-01,\n",
       "          1.92170843e-01, -1.33796483e-01],\n",
       "        [-1.96946934e-01,  2.25027502e-02, -2.49532312e-02,\n",
       "         -1.06456429e-02, -1.19735897e-02, -3.06161344e-02,\n",
       "          1.56417951e-01, -1.18641786e-01],\n",
       "        [-8.02473277e-02,  4.41469103e-02, -8.62051100e-02,\n",
       "         -1.42608792e-01,  7.85285980e-02, -2.04367474e-01,\n",
       "          1.91205740e-02, -1.88183933e-02],\n",
       "        [-8.82475972e-02,  1.34595498e-01, -6.05747998e-02,\n",
       "          1.37400135e-01,  1.46622792e-01, -4.07832861e-02,\n",
       "         -5.17740846e-02, -1.25611871e-02],\n",
       "        [ 3.83581221e-03,  1.54156536e-02, -5.47210127e-02,\n",
       "          2.34136432e-02, -1.53329045e-01, -1.49508476e-01,\n",
       "         -1.50805578e-01,  4.96308655e-02],\n",
       "        [-2.06808016e-01, -1.56938121e-01, -2.60832906e-03,\n",
       "         -1.68949440e-01, -2.09987298e-01,  1.69947162e-01,\n",
       "         -1.34525180e-01, -1.00215264e-01],\n",
       "        [ 1.42209992e-01,  3.70083600e-02, -2.04409212e-02,\n",
       "         -1.94008082e-01, -8.16267282e-02,  4.45048958e-02,\n",
       "         -1.35999143e-01,  1.94289431e-01],\n",
       "        [ 9.86320227e-02, -3.25584710e-02,  2.12595835e-01,\n",
       "          5.36147505e-02,  8.19050223e-02,  1.86943308e-01,\n",
       "         -1.49156466e-01,  1.42656669e-01],\n",
       "        [ 6.16462082e-02,  5.06183952e-02, -7.35421628e-02,\n",
       "         -3.43655050e-03, -1.28168955e-01,  5.66311330e-02,\n",
       "          2.04123154e-01,  2.07837209e-01],\n",
       "        [-1.24748789e-01,  8.09183270e-02, -3.32813859e-02,\n",
       "         -1.18314534e-01, -2.64933407e-02,  6.83472902e-02,\n",
       "          1.66933224e-01,  7.26264268e-02],\n",
       "        [-2.23727822e-02,  5.92057556e-02,  1.56695530e-01,\n",
       "         -7.97634721e-02,  1.69106051e-01, -9.39078480e-02,\n",
       "         -1.33375525e-01,  1.41699716e-01],\n",
       "        [-1.88900352e-01,  1.99115381e-01, -1.64345965e-01,\n",
       "         -1.56967312e-01,  3.91667932e-02,  5.69729954e-02,\n",
       "          5.61467260e-02,  5.35073727e-02],\n",
       "        [ 1.67650118e-01,  2.08742663e-01,  9.24554616e-02,\n",
       "          1.56910494e-01, -5.18877655e-02, -2.12643906e-01,\n",
       "         -3.72202098e-02, -1.53560340e-02],\n",
       "        [-8.87995511e-02,  1.44817725e-01, -2.85894722e-02,\n",
       "          5.43626398e-02,  5.59707135e-02,  1.82625189e-01,\n",
       "         -1.54984191e-01, -2.10239366e-01],\n",
       "        [-7.90700614e-02, -1.46437168e-01, -1.09404929e-01,\n",
       "          2.00404808e-01,  1.87477872e-01,  1.60208151e-01,\n",
       "          1.07168749e-01, -2.15093821e-01],\n",
       "        [-1.28040135e-01,  6.77383691e-02,  2.90925652e-02,\n",
       "          5.95549494e-02, -1.62704036e-01,  1.81537464e-01,\n",
       "         -1.85404122e-01, -1.65567204e-01],\n",
       "        [-1.52685627e-01,  6.97458535e-02, -1.13673083e-01,\n",
       "         -8.02426487e-02, -4.39102352e-02, -2.04586878e-01,\n",
       "         -1.31063700e-01,  3.37004215e-02],\n",
       "        [ 1.25647351e-01, -2.15564370e-02, -9.39721540e-02,\n",
       "          9.21874195e-02,  8.73426944e-02, -1.24570757e-01,\n",
       "         -3.27257812e-02, -8.71437937e-02],\n",
       "        [ 5.21952063e-02, -2.16809615e-01,  1.40419379e-01,\n",
       "          3.75926644e-02, -1.00917578e-01,  6.26008064e-02,\n",
       "          1.18807957e-01,  6.68820739e-03],\n",
       "        [ 8.41449946e-02, -6.28833473e-02,  1.84005395e-01,\n",
       "          4.41798419e-02,  1.43289402e-01,  1.60571560e-01,\n",
       "         -1.73456922e-01, -8.89741033e-02],\n",
       "        [-6.00300729e-03, -2.41807401e-02, -1.73119932e-01,\n",
       "         -6.79760277e-02, -1.65248692e-01, -1.56249180e-01,\n",
       "         -6.31372482e-02,  3.06151509e-02],\n",
       "        [-3.52054983e-02,  1.83439106e-02,  6.21797889e-02,\n",
       "         -1.07921064e-02,  1.51165709e-01,  4.03819531e-02,\n",
       "          1.90073207e-01, -1.35381132e-01],\n",
       "        [ 1.62902161e-01, -1.65822655e-02,  1.77166298e-01,\n",
       "         -7.66016543e-03, -9.69423354e-03,  4.31641191e-02,\n",
       "         -1.23602323e-01, -6.20444715e-02],\n",
       "        [-1.50377452e-01, -1.34144127e-01,  4.61899191e-02,\n",
       "         -8.80425125e-02,  7.15203434e-02, -3.83064896e-02,\n",
       "          1.21365085e-01, -7.45613277e-02],\n",
       "        [ 2.31540799e-02, -1.09695449e-01, -1.45643905e-01,\n",
       "          1.88740894e-01, -1.52035341e-01, -1.06532663e-01,\n",
       "         -1.77320614e-01,  1.05637029e-01],\n",
       "        [-1.95746094e-01, -2.09058821e-02,  6.30931705e-02,\n",
       "          8.56409967e-03, -6.92267716e-02,  1.96845978e-02,\n",
       "         -1.85806617e-01, -4.59976047e-02],\n",
       "        [ 2.28194892e-02,  2.05414891e-02, -1.68175995e-01,\n",
       "          1.38715968e-01,  3.46436054e-02,  1.17082104e-01,\n",
       "          2.29073614e-02, -1.68218613e-01],\n",
       "        [-7.46226311e-03, -1.27108485e-01, -1.99431658e-01,\n",
       "         -2.04743743e-02, -3.83655280e-02,  2.43653357e-03,\n",
       "          3.24539393e-02, -8.12175870e-02]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.7227796 ],\n",
       "        [-0.460723  ],\n",
       "        [ 0.23796237],\n",
       "        [-0.30549222],\n",
       "        [-0.7163281 ],\n",
       "        [ 0.5303812 ],\n",
       "        [ 0.4651897 ],\n",
       "        [-0.03967994]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model.output_shape\n",
    "# Model summary\n",
    "model.summary()\n",
    "# Model config\n",
    "model.get_config()\n",
    "# List all weight tensors \n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nanelia/opt/anaconda3/envs/my-project/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:357: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3/3 [==============================] - 23s 533ms/step - loss: 0.7568 - accuracy: 0.4892 - mean_pred: 0.4364 - val_loss: 0.9100 - val_accuracy: 0.1714 - val_mean_pred: 0.4191\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.90998, saving model to lstm.hdf5\n",
      "Epoch 2/60\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.7717 - accuracy: 0.4448 - mean_pred: 0.4373 - val_loss: 0.9082 - val_accuracy: 0.1714 - val_mean_pred: 0.4195\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.90998 to 0.90822, saving model to lstm.hdf5\n",
      "Epoch 3/60\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7673 - accuracy: 0.4659 - mean_pred: 0.4463 - val_loss: 0.9064 - val_accuracy: 0.1714 - val_mean_pred: 0.4199\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.90822 to 0.90642, saving model to lstm.hdf5\n",
      "Epoch 4/60\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7935 - accuracy: 0.4389 - mean_pred: 0.4433 - val_loss: 0.9039 - val_accuracy: 0.1714 - val_mean_pred: 0.4206\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.90642 to 0.90394, saving model to lstm.hdf5\n",
      "Epoch 5/60\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.7542 - accuracy: 0.4764 - mean_pred: 0.4378 - val_loss: 0.9019 - val_accuracy: 0.1714 - val_mean_pred: 0.4212\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.90394 to 0.90186, saving model to lstm.hdf5\n",
      "Epoch 6/60\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7726 - accuracy: 0.4593 - mean_pred: 0.4418 - val_loss: 0.8996 - val_accuracy: 0.1714 - val_mean_pred: 0.4219\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.90186 to 0.89964, saving model to lstm.hdf5\n",
      "Epoch 7/60\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7738 - accuracy: 0.4984 - mean_pred: 0.4422 - val_loss: 0.8973 - val_accuracy: 0.1714 - val_mean_pred: 0.4226\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.89964 to 0.89735, saving model to lstm.hdf5\n",
      "Epoch 8/60\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7565 - accuracy: 0.5002 - mean_pred: 0.4422 - val_loss: 0.8954 - val_accuracy: 0.1714 - val_mean_pred: 0.4232\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.89735 to 0.89539, saving model to lstm.hdf5\n",
      "Epoch 9/60\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7659 - accuracy: 0.4792 - mean_pred: 0.4450 - val_loss: 0.8931 - val_accuracy: 0.1714 - val_mean_pred: 0.4239\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.89539 to 0.89313, saving model to lstm.hdf5\n",
      "Epoch 10/60\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7565 - accuracy: 0.4471 - mean_pred: 0.4496 - val_loss: 0.8911 - val_accuracy: 0.1714 - val_mean_pred: 0.4245\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.89313 to 0.89111, saving model to lstm.hdf5\n",
      "Epoch 11/60\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7371 - accuracy: 0.5161 - mean_pred: 0.4406 - val_loss: 0.8887 - val_accuracy: 0.1714 - val_mean_pred: 0.4253\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.89111 to 0.88870, saving model to lstm.hdf5\n",
      "Epoch 12/60\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7529 - accuracy: 0.4984 - mean_pred: 0.4411 - val_loss: 0.8860 - val_accuracy: 0.1714 - val_mean_pred: 0.4262\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.88870 to 0.88605, saving model to lstm.hdf5\n",
      "Epoch 13/60\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7475 - accuracy: 0.5148 - mean_pred: 0.4420 - val_loss: 0.8830 - val_accuracy: 0.1714 - val_mean_pred: 0.4273\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.88605 to 0.88305, saving model to lstm.hdf5\n",
      "Epoch 14/60\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7421 - accuracy: 0.5003 - mean_pred: 0.4465 - val_loss: 0.8803 - val_accuracy: 0.1714 - val_mean_pred: 0.4282\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.88305 to 0.88029, saving model to lstm.hdf5\n",
      "Epoch 15/60\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7498 - accuracy: 0.4714 - mean_pred: 0.4471 - val_loss: 0.8776 - val_accuracy: 0.1714 - val_mean_pred: 0.4291\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.88029 to 0.87755, saving model to lstm.hdf5\n",
      "Epoch 16/60\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7358 - accuracy: 0.5004 - mean_pred: 0.4446 - val_loss: 0.8750 - val_accuracy: 0.1714 - val_mean_pred: 0.4300\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.87755 to 0.87498, saving model to lstm.hdf5\n",
      "Epoch 17/60\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7390 - accuracy: 0.5082 - mean_pred: 0.4479 - val_loss: 0.8727 - val_accuracy: 0.1714 - val_mean_pred: 0.4308\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.87498 to 0.87272, saving model to lstm.hdf5\n",
      "Epoch 18/60\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7469 - accuracy: 0.4918 - mean_pred: 0.4419 - val_loss: 0.8708 - val_accuracy: 0.1714 - val_mean_pred: 0.4314\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.87272 to 0.87076, saving model to lstm.hdf5\n",
      "Epoch 19/60\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7467 - accuracy: 0.5236 - mean_pred: 0.4422 - val_loss: 0.8682 - val_accuracy: 0.1714 - val_mean_pred: 0.4323\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.87076 to 0.86820, saving model to lstm.hdf5\n",
      "Epoch 20/60\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7549 - accuracy: 0.4583 - mean_pred: 0.4421 - val_loss: 0.8654 - val_accuracy: 0.1714 - val_mean_pred: 0.4333\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.86820 to 0.86541, saving model to lstm.hdf5\n",
      "Epoch 21/60\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.7470 - accuracy: 0.4828 - mean_pred: 0.4489 - val_loss: 0.8630 - val_accuracy: 0.1714 - val_mean_pred: 0.4341\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.86541 to 0.86297, saving model to lstm.hdf5\n",
      "Epoch 22/60\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.7387 - accuracy: 0.4765 - mean_pred: 0.4547 - val_loss: 0.8606 - val_accuracy: 0.1714 - val_mean_pred: 0.4349\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.86297 to 0.86065, saving model to lstm.hdf5\n",
      "Epoch 23/60\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7570 - accuracy: 0.4914 - mean_pred: 0.4486 - val_loss: 0.8586 - val_accuracy: 0.2000 - val_mean_pred: 0.4355\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.86065 to 0.85863, saving model to lstm.hdf5\n",
      "Epoch 24/60\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7356 - accuracy: 0.4927 - mean_pred: 0.4467 - val_loss: 0.8568 - val_accuracy: 0.2000 - val_mean_pred: 0.4361\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.85863 to 0.85677, saving model to lstm.hdf5\n",
      "Epoch 25/60\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7300 - accuracy: 0.4992 - mean_pred: 0.4499 - val_loss: 0.8548 - val_accuracy: 0.2000 - val_mean_pred: 0.4368\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.85677 to 0.85477, saving model to lstm.hdf5\n",
      "Epoch 26/60\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.7369 - accuracy: 0.4915 - mean_pred: 0.4536 - val_loss: 0.8533 - val_accuracy: 0.2000 - val_mean_pred: 0.4373\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.85477 to 0.85326, saving model to lstm.hdf5\n",
      "Epoch 27/60\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7243 - accuracy: 0.5256 - mean_pred: 0.4524 - val_loss: 0.8521 - val_accuracy: 0.2000 - val_mean_pred: 0.4376\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.85326 to 0.85210, saving model to lstm.hdf5\n",
      "Epoch 28/60\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.7311 - accuracy: 0.5134 - mean_pred: 0.4455 - val_loss: 0.8509 - val_accuracy: 0.2000 - val_mean_pred: 0.4379\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.85210 to 0.85087, saving model to lstm.hdf5\n",
      "Epoch 29/60\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7303 - accuracy: 0.4949 - mean_pred: 0.4443 - val_loss: 0.8497 - val_accuracy: 0.2000 - val_mean_pred: 0.4382\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.85087 to 0.84968, saving model to lstm.hdf5\n",
      "Epoch 30/60\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7409 - accuracy: 0.5025 - mean_pred: 0.4481 - val_loss: 0.8484 - val_accuracy: 0.2286 - val_mean_pred: 0.4386\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.84968 to 0.84844, saving model to lstm.hdf5\n",
      "Epoch 31/60\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7229 - accuracy: 0.5263 - mean_pred: 0.4492 - val_loss: 0.8473 - val_accuracy: 0.2286 - val_mean_pred: 0.4390\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.84844 to 0.84727, saving model to lstm.hdf5\n",
      "Epoch 32/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7244 - accuracy: 0.5226 - mean_pred: 0.4466 - val_loss: 0.8461 - val_accuracy: 0.2286 - val_mean_pred: 0.4393\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.84727 to 0.84612, saving model to lstm.hdf5\n",
      "Epoch 33/60\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7565 - accuracy: 0.4632 - mean_pred: 0.4486 - val_loss: 0.8452 - val_accuracy: 0.2286 - val_mean_pred: 0.4395\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.84612 to 0.84521, saving model to lstm.hdf5\n",
      "Epoch 34/60\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7392 - accuracy: 0.5101 - mean_pred: 0.4501 - val_loss: 0.8441 - val_accuracy: 0.2286 - val_mean_pred: 0.4399\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.84521 to 0.84414, saving model to lstm.hdf5\n",
      "Epoch 35/60\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7409 - accuracy: 0.5010 - mean_pred: 0.4538 - val_loss: 0.8432 - val_accuracy: 0.2000 - val_mean_pred: 0.4402\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.84414 to 0.84316, saving model to lstm.hdf5\n",
      "Epoch 36/60\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7235 - accuracy: 0.5173 - mean_pred: 0.4530 - val_loss: 0.8425 - val_accuracy: 0.2000 - val_mean_pred: 0.4403\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.84316 to 0.84253, saving model to lstm.hdf5\n",
      "Epoch 37/60\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7269 - accuracy: 0.4960 - mean_pred: 0.4470 - val_loss: 0.8416 - val_accuracy: 0.2000 - val_mean_pred: 0.4406\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.84253 to 0.84162, saving model to lstm.hdf5\n",
      "Epoch 38/60\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7285 - accuracy: 0.4899 - mean_pred: 0.4474 - val_loss: 0.8406 - val_accuracy: 0.2000 - val_mean_pred: 0.4409\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.84162 to 0.84063, saving model to lstm.hdf5\n",
      "Epoch 39/60\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7286 - accuracy: 0.4887 - mean_pred: 0.4487 - val_loss: 0.8393 - val_accuracy: 0.2000 - val_mean_pred: 0.4413\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.84063 to 0.83931, saving model to lstm.hdf5\n",
      "Epoch 40/60\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7187 - accuracy: 0.5244 - mean_pred: 0.4498 - val_loss: 0.8380 - val_accuracy: 0.2000 - val_mean_pred: 0.4417\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.83931 to 0.83805, saving model to lstm.hdf5\n",
      "Epoch 41/60\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7352 - accuracy: 0.5257 - mean_pred: 0.4538 - val_loss: 0.8370 - val_accuracy: 0.2000 - val_mean_pred: 0.4421\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.83805 to 0.83703, saving model to lstm.hdf5\n",
      "Epoch 42/60\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7153 - accuracy: 0.5073 - mean_pred: 0.4591 - val_loss: 0.8362 - val_accuracy: 0.2000 - val_mean_pred: 0.4423\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.83703 to 0.83623, saving model to lstm.hdf5\n",
      "Epoch 43/60\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7132 - accuracy: 0.5362 - mean_pred: 0.4573 - val_loss: 0.8354 - val_accuracy: 0.2000 - val_mean_pred: 0.4426\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.83623 to 0.83538, saving model to lstm.hdf5\n",
      "Epoch 44/60\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7226 - accuracy: 0.5281 - mean_pred: 0.4458 - val_loss: 0.8342 - val_accuracy: 0.2000 - val_mean_pred: 0.4429\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.83538 to 0.83424, saving model to lstm.hdf5\n",
      "Epoch 45/60\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7070 - accuracy: 0.5672 - mean_pred: 0.4480 - val_loss: 0.8327 - val_accuracy: 0.2000 - val_mean_pred: 0.4435\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.83424 to 0.83274, saving model to lstm.hdf5\n",
      "Epoch 46/60\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7131 - accuracy: 0.5231 - mean_pred: 0.4575 - val_loss: 0.8316 - val_accuracy: 0.2000 - val_mean_pred: 0.4439\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.83274 to 0.83164, saving model to lstm.hdf5\n",
      "Epoch 47/60\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7461 - accuracy: 0.5032 - mean_pred: 0.4522 - val_loss: 0.8306 - val_accuracy: 0.2000 - val_mean_pred: 0.4442\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.83164 to 0.83060, saving model to lstm.hdf5\n",
      "Epoch 48/60\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.7075 - accuracy: 0.5080 - mean_pred: 0.4547 - val_loss: 0.8296 - val_accuracy: 0.2000 - val_mean_pred: 0.4446\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.83060 to 0.82958, saving model to lstm.hdf5\n",
      "Epoch 49/60\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7042 - accuracy: 0.5338 - mean_pred: 0.4550 - val_loss: 0.8284 - val_accuracy: 0.2000 - val_mean_pred: 0.4449\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.82958 to 0.82843, saving model to lstm.hdf5\n",
      "Epoch 50/60\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7185 - accuracy: 0.5278 - mean_pred: 0.4459 - val_loss: 0.8272 - val_accuracy: 0.2000 - val_mean_pred: 0.4454\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.82843 to 0.82715, saving model to lstm.hdf5\n",
      "Epoch 51/60\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7210 - accuracy: 0.5367 - mean_pred: 0.4514 - val_loss: 0.8259 - val_accuracy: 0.2000 - val_mean_pred: 0.4458\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.82715 to 0.82591, saving model to lstm.hdf5\n",
      "Epoch 52/60\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7108 - accuracy: 0.5512 - mean_pred: 0.4484 - val_loss: 0.8248 - val_accuracy: 0.2000 - val_mean_pred: 0.4462\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.82591 to 0.82482, saving model to lstm.hdf5\n",
      "Epoch 53/60\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7185 - accuracy: 0.5200 - mean_pred: 0.4494 - val_loss: 0.8237 - val_accuracy: 0.2000 - val_mean_pred: 0.4466\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.82482 to 0.82375, saving model to lstm.hdf5\n",
      "Epoch 54/60\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.7121 - accuracy: 0.5541 - mean_pred: 0.4557 - val_loss: 0.8227 - val_accuracy: 0.2000 - val_mean_pred: 0.4470\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.82375 to 0.82270, saving model to lstm.hdf5\n",
      "Epoch 55/60\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7059 - accuracy: 0.5301 - mean_pred: 0.4503 - val_loss: 0.8214 - val_accuracy: 0.2000 - val_mean_pred: 0.4475\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.82270 to 0.82136, saving model to lstm.hdf5\n",
      "Epoch 56/60\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.7157 - accuracy: 0.5429 - mean_pred: 0.4525 - val_loss: 0.8201 - val_accuracy: 0.2000 - val_mean_pred: 0.4480\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.82136 to 0.82007, saving model to lstm.hdf5\n",
      "Epoch 57/60\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7096 - accuracy: 0.5364 - mean_pred: 0.4516 - val_loss: 0.8189 - val_accuracy: 0.2000 - val_mean_pred: 0.4484\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.82007 to 0.81888, saving model to lstm.hdf5\n",
      "Epoch 58/60\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7107 - accuracy: 0.5223 - mean_pred: 0.4549 - val_loss: 0.8176 - val_accuracy: 0.2000 - val_mean_pred: 0.4489\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.81888 to 0.81758, saving model to lstm.hdf5\n",
      "Epoch 59/60\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7061 - accuracy: 0.5538 - mean_pred: 0.4538 - val_loss: 0.8164 - val_accuracy: 0.2000 - val_mean_pred: 0.4493\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.81758 to 0.81638, saving model to lstm.hdf5\n",
      "Epoch 60/60\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7003 - accuracy: 0.5543 - mean_pred: 0.4521 - val_loss: 0.8152 - val_accuracy: 0.2000 - val_mean_pred: 0.4498\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.81638 to 0.81523, saving model to lstm.hdf5\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from keras.optimizers import adam_v2\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "opt = adam_v2.Adam(lr=0.0001)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss={'main_output': 'binary_crossentropy'},metrics=['accuracy',mean_pred])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath='lstm.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "history=model.fit({'main_input': X_train_temporal, 'aux_input': X_train_cat},\n",
    "          {'main_output': y_train},\n",
    "          epochs=60, batch_size=128, callbacks=[reduce_lr, checkpointer],validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('lstm.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = model.predict({'main_input': X_test_temporal, 'aux_input': X_test_cat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, average_precision_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6639999999999999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42777777777777776"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83        25\n",
      "           1       0.29      0.40      0.33         5\n",
      "\n",
      "    accuracy                           0.73        30\n",
      "   macro avg       0.58      0.60      0.58        30\n",
      "weighted avg       0.77      0.73      0.75        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, (y_score>0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-project",
   "language": "python",
   "name": "my-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
